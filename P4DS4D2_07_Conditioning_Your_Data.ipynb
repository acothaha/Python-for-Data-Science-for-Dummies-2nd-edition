{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out what is in your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Number  String Boolean\n",
      "0      1   First    True\n",
      "1      2  Second   False\n",
      "2      3   Third    True\n",
      "3      3   Third    True\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n",
      "\n",
      "3    True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "from lxml import objectify\n",
    "import pandas as pd\n",
    "\n",
    "xml = objectify.parse(open('dataset_toy/XMLData2.xml'))\n",
    "root = xml.getroot()\n",
    "df = pd.DataFrame(columns=('Number', 'String', 'Boolean'))\n",
    "\n",
    "for i in range(0,4):\n",
    "    obj = root.getchildren()[i].getchildren()\n",
    "    row = dict(zip(['Number', 'String', 'Boolean'], \n",
    "                   [obj[0].text, obj[1].text, \n",
    "                    obj[2].text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    df = df.append(row_s)\n",
    "\n",
    "# creating a search object containing a list of\n",
    "# duplicated rows by calling pd.DataFrame.duplicated()\n",
    "search = pd.DataFrame.duplicated(df)\n",
    "print(df)\n",
    "print()\n",
    "# displaying the list in the search list\n",
    "print(search)\n",
    "print()\n",
    "# displaying only the row that have a boolean value of True\n",
    "# which means that particular row is a duplicate\n",
    "print(search[search == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Number  String Boolean\n",
      "0      1   First    True\n",
      "1      2  Second   False\n",
      "2      3   Third    True\n"
     ]
    }
   ],
   "source": [
    "from lxml import objectify\n",
    "import pandas as pd\n",
    "\n",
    "xml = objectify.parse(open('dataset_toy/XMLData2.xml'))\n",
    "root = xml.getroot()\n",
    "df = pd.DataFrame(columns=('Number', 'String', 'Boolean'))\n",
    "\n",
    "for i in range(0,4):\n",
    "    obj = root.getchildren()[i].getchildren()\n",
    "    row = dict(zip(['Number', 'String', 'Boolean'], \n",
    "                   [obj[0].text, obj[1].text, \n",
    "                    obj[2].text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    df = df.append(row_s)\n",
    "\n",
    "# just by calling drop_duplicates() you can\n",
    "# easily remove the errant recordb\n",
    "print(df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a data map and data plan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      B                                            \\\n",
      "  count mean       std  min   25%  50%   75%  max   \n",
      "A                                                   \n",
      "0   5.0  3.0  1.581139  1.0  2.00  3.0  4.00  5.0   \n",
      "1   2.0  3.5  2.121320  2.0  2.75  3.5  4.25  5.0   \n",
      "\n",
      "      C                                            \n",
      "  count mean       std  min   25%  50%   75%  max  \n",
      "A                                                  \n",
      "0   5.0  2.8  1.788854  1.0  1.00  3.0  4.00  5.0  \n",
      "1   2.0  2.5  0.707107  2.0  2.25  2.5  2.75  3.0  \n",
      "                B         C\n",
      "A                          \n",
      "0 count  5.000000  5.000000\n",
      "  mean   3.000000  2.800000\n",
      "  std    1.581139  1.788854\n",
      "  min    1.000000  1.000000\n",
      "  25%    2.000000  1.000000\n",
      "  50%    3.000000  3.000000\n",
      "  75%    4.000000  4.000000\n",
      "  max    5.000000  5.000000\n",
      "1 count  2.000000  2.000000\n",
      "  mean   3.500000  2.500000\n",
      "  std    2.121320  0.707107\n",
      "  min    2.000000  2.000000\n",
      "  25%    2.750000  2.250000\n",
      "  50%    3.500000  2.500000\n",
      "  75%    4.250000  2.750000\n",
      "  max    5.000000  3.000000\n",
      "      B          C     \n",
      "  count mean count mean\n",
      "A                      \n",
      "0   5.0  3.0   5.0  2.8\n",
      "1   2.0  3.5   2.0  2.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# set a maximum display.width by 55 character\n",
    "pd.set_option('display.width', 55)\n",
    "\n",
    "# creating a df that contains 3 dict items, which later\n",
    "# will be grouped by the value of the first item, so\n",
    "# later there will wbe only two datasets with 2 serieses\n",
    "df = pd.DataFrame({'A': [0, 0, 0, 0, 0, 1, 1], \n",
    "                   'B': [1, 2, 3, 5, 4, 2, 5],\n",
    "                   'C': [5, 3, 4, 1, 1, 2, 3]})\n",
    "\n",
    "# grouping earlier df and uses dataset 'A' as the indicator\n",
    "# by calling groupby() and calling describe() to obtain \n",
    "# statistics of each series in each datasets\n",
    "a_group_desc = df.groupby('A').describe()\n",
    "print(a_group_desc)\n",
    "\n",
    "# for a more compact presentation you can stack the data\n",
    "stacked = a_group_desc.stack()\n",
    "print(stacked)\n",
    "\n",
    "# if you just want to display a certain statistics\n",
    "# using loc() lets you obtain specific column\n",
    "print(a_group_desc.loc[:,(slice(None), ['count', 'mean']),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Categorical Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Blue\n",
      "1      Red\n",
      "2    Green\n",
      "dtype: category\n",
      "Categories (3, object): [Blue, Green, Red]\n",
      "\n",
      "0      NaN\n",
      "1    Green\n",
      "2      Red\n",
      "3     Blue\n",
      "4      NaN\n",
      "dtype: category\n",
      "Categories (3, object): [Blue, Green, Red]\n",
      "\n",
      "0    True\n",
      "4    True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# creating a categorical variable, car_colors\n",
    "car_colors = pd.Series(['Blue', 'Red', 'Green'],\n",
    "                        dtype='category') #specify the dtype\n",
    "\n",
    "# list of actual car colors and using previous variable as\n",
    "# the categories, and match it with the predefined acceptable\n",
    "# values, when there are not match, it will output NaN\n",
    "car_data = pd.Series(\n",
    "    pd.Categorical(\n",
    "        ['Yellow', 'Green', 'Red', 'Blue', 'Purple'],\n",
    "            categories=car_colors, ordered=False))\n",
    "\n",
    "# locating the car_data items that has NaN value\n",
    "find_entries = pd.isnull(car_data)\n",
    "\n",
    "print(car_colors)\n",
    "print()\n",
    "print(car_data)\n",
    "print()\n",
    "print(find_entries[find_entries == True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming Levels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Purple\n",
      "1    Yellow\n",
      "2     Mauve\n",
      "3    Purple\n",
      "4     Mauve\n",
      "dtype: category\n",
      "Categories (3, object): [Purple, Yellow, Mauve]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "car_colors = pd.Series(['Blue', 'Red', 'Green'],\n",
    "                        dtype='category')\n",
    "car_data = pd.Series(\n",
    "    pd.Categorical(\n",
    "        ['Blue', 'Green', 'Red', 'Blue', 'Red'],\n",
    "            categories=car_colors, ordered=False))\n",
    "\n",
    "# using cat.categories() to set a new value\n",
    "car_colors.cat.categories = ['Purple', 'Yellow', 'Mauve']\n",
    "car_data.cat.categories = car_colors\n",
    "\n",
    "print(car_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining levels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    Red\n",
      "4    Red\n",
      "dtype: category\n",
      "Categories (4, object): [Blue, Red, Green, Blue_Red]\n",
      "\n",
      "0    Blue_Red\n",
      "1       Green\n",
      "2    Blue_Red\n",
      "3       Green\n",
      "4    Blue_Red\n",
      "5       Green\n",
      "dtype: category\n",
      "Categories (2, object): [Green, Blue_Red]\n"
     ]
    }
   ],
   "source": [
    "car_colors = pd.Series(['Blue', 'Red', 'Green'],\n",
    "                        dtype='category')\n",
    "car_data = pd.Series(\n",
    "    pd.Categorical(\n",
    "        ['Blue', 'Green', 'Red', 'Green', 'Red', 'Green'],\n",
    "            categories=car_colors, ordered=False))\n",
    "\n",
    "# Adding Blue_Red category to car_data\n",
    "car_data = car_data.cat.set_categories(\n",
    "    ['Blue', 'Red', 'Green', 'Blue_Red'])\n",
    "# locating 'Red' in car_data and printing it\n",
    "print (car_data.loc[car_data.isin(['Red'])])\n",
    "# locating 'Red' and change its value to 'Red_Blue'\n",
    "car_data.loc[car_data.isin(['Red'])] = 'Blue_Red'\n",
    "# locating 'Blue' and change its value to 'Red_Blue'\n",
    "car_data.loc[car_data.isin(['Blue'])] = 'Blue_Red'\n",
    "\n",
    "# setting the cateogories just to \"Green\" and \"Blue_Red\"\n",
    "car_data = car_data.cat.set_categories(\n",
    "    [\"Green\", \"Blue_Red\"])\n",
    "\n",
    "print()\n",
    "print(car_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Date in Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting date and time values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-14 15:54:29.379967\n",
      "Sun, 14 June 2020\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# Assigning current time to variable now\n",
    "now = dt.datetime.now()\n",
    "\n",
    "# displaying variable now as a string\n",
    "print(str(now))\n",
    "# transforming variable now into a string with a specific defining\n",
    "# %a : the abrreviation of the day\n",
    "# %d : date\n",
    "# %B : Month\n",
    "# %Y : Year\n",
    "print(now.strftime('%a, %d %B %Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the right time transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:59:16\n",
      "17:59:16\n",
      "2:00:00\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "now = dt.datetime.now()\n",
    "# Transforming one time into another time with timedelta()\n",
    "# you can use : days, seconds, minutes, hours, weeks\n",
    "timevalue = now + dt.timedelta(hours=2)\n",
    "\n",
    "# %H : Hour\n",
    "# %M : Minute\n",
    "# %S : Second\n",
    "print(now.strftime('%H:%M:%S'))\n",
    "print(timevalue.strftime('%H:%M:%S'))\n",
    "print(timevalue - now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Missing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    NaN\n",
      "4    5.0\n",
      "5    6.0\n",
      "6    NaN\n",
      "dtype: float64\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "dtype: bool\n",
      "\n",
      "3   NaN\n",
      "6   NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# build a df with two missing data\n",
    "# represented by np.Nan (using numpy)\n",
    "# and None (using python)\n",
    "s = pd.Series([1, 2, 3, np.NaN, 5, 6, None])\n",
    "\n",
    "print(s)\n",
    "print()\n",
    "# Displaying all the data and assign \n",
    "# False value to the non-missing data\n",
    "# and True to the missing data\n",
    "print(s.isnull())\n",
    "\n",
    "print()\n",
    "# Showing only the data that have the missing data\n",
    "print(s[s.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filling in missing data or dropping it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    NaN\n",
      "4    5.0\n",
      "5    6.0\n",
      "6    NaN\n",
      "dtype: float64\n",
      "\n",
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    5.0\n",
      "5    6.0\n",
      "6    3.0\n",
      "dtype: float64\n",
      "\n",
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "4    5.0\n",
      "5    6.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([1, 2, 3, np.NaN, 5, 6, None])\n",
    "\n",
    "print(s)\n",
    "print()\n",
    "# filling the missing data with the mean of the data\n",
    "print(s.fillna(int(s.mean())))\n",
    "print()\n",
    "# dropping the missing data\n",
    "print(s.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    4.0\n",
      "4    5.0\n",
      "5    6.0\n",
      "6    7.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# list with some missing values\n",
    "s = [[1, 2, 3, np.NaN, 5, 6, None]]\n",
    "\n",
    "# creating a imputer to replace the missing value\n",
    "# with stratigey parameter to define how to replace the missing data\n",
    "# you can use mean, median and most_frequent as the arguments\n",
    "imp = SimpleImputer(missing_values=np.nan,\n",
    "             strategy='mean')\n",
    "\n",
    "# provide the statistics for the imputer to use by calling fit()\n",
    "imp.fit([[1, 2, 3, 4, 5, 6, 7]])\n",
    "\n",
    "# calling transfomr in s to fill the missing data\n",
    "# and start with index 0 by using tolist()\n",
    "x = pd.Series(imp.transform(s).tolist()[0])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing and Dicing: Filtering and Selecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]\n",
      "  [ 7  8  9]]\n",
      "\n",
      " [[11 12 13]\n",
      "  [14 15 16]\n",
      "  [17 18 19]]\n",
      "\n",
      " [[21 22 23]\n",
      "  [24 25 26]\n",
      "  [27 28 29]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11, 12, 13],\n",
       "       [14, 15, 16],\n",
       "       [17, 18, 19]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a 3-D array\n",
    "x = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9],],\n",
    "              [[11,12,13], [14,15,16], [17,18,19],], \n",
    "              [[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "print(x)\n",
    "\n",
    "# slicing row 1 from 3-D array x\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]\n",
      "  [ 7  8  9]]\n",
      "\n",
      " [[11 12 13]\n",
      "  [14 15 16]\n",
      "  [17 18 19]]\n",
      "\n",
      " [[21 22 23]\n",
      "  [24 25 26]\n",
      "  [27 28 29]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5,  6],\n",
       "       [14, 15, 16],\n",
       "       [24, 25, 26]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9],],\n",
    "              [[11,12,13], [14,15,16], [17,18,19],], \n",
    "              [[21,22,23], [24,25,26], [27,28,29]]])\n",
    "print(x)\n",
    "# slicing the entire rows using (:)\n",
    "# in the column 1\n",
    "x[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]\n",
      "  [ 7  8  9]]\n",
      "\n",
      " [[11 12 13]\n",
      "  [14 15 16]\n",
      "  [17 18 19]]\n",
      "\n",
      " [[21 22 23]\n",
      "  [24 25 26]\n",
      "  [27 28 29]]]\n",
      "\n",
      "[24 25 26]\n",
      "[ 2 12 22]\n",
      "[13 16 19]\n",
      "\n",
      "[[[14 15 16]\n",
      "  [17 18 19]]\n",
      "\n",
      " [[24 25 26]\n",
      "  [27 28 29]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9],],\n",
    "              [[11,12,13], [14,15,16], [17,18,19],], \n",
    "              [[21,22,23], [24,25,26], [27,28,29]]])\n",
    "print(x)\n",
    "print()\n",
    "# dicing the row 2 from column 1\n",
    "print(x[2,1])\n",
    "# dicing the item 1 from every row in column 0\n",
    "print(x[:,0,1])\n",
    "# dicing item 2 in row 1 from every column\n",
    "print(x[1,:,2])\n",
    "print()\n",
    "# dicing rows 1 and 2 in columns 1 and 2\n",
    "print(x[1:3, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating and Transforming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new cases and variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  2  1  5\n",
      "1  3  2  3\n",
      "2  1  3  4\n",
      "\n",
      "   A  B  C\n",
      "0  2  1  5\n",
      "1  3  2  3\n",
      "2  1  3  4\n",
      "0  4  4  4\n",
      "\n",
      "   A  B  C\n",
      "0  2  1  5\n",
      "1  3  2  3\n",
      "2  1  3  4\n",
      "3  4  4  4\n",
      "\n",
      "   A  B  C\n",
      "0  2  1  5\n",
      "1  3  2  3\n",
      "2  1  3  4\n",
      "3  4  4  4\n",
      "4  5  5  5\n",
      "\n",
      "   A  B  C  D\n",
      "0  2  1  5  1\n",
      "1  3  2  3  2\n",
      "2  1  3  4  3\n",
      "3  4  4  4  4\n",
      "4  5  5  5  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# creating a df\n",
    "df = pd.DataFrame({'A': [2, 3, 1], \n",
    "                   'B': [1, 2, 3],\n",
    "                   'C': [5, 3, 4]})\n",
    "\n",
    "# the df which later will be appended into the other one\n",
    "df1 = pd.DataFrame({'A': [4], \n",
    "                   'B': [4],\n",
    "                   'C': [4]})\n",
    "print(df)\n",
    "print()\n",
    "# appending df1 into df ( just adding a new row)\n",
    "df = df.append(df1)\n",
    "print(df)\n",
    "print()\n",
    "# resetting the index of df\n",
    "# the drop parameter funtions (default: False) \n",
    "# to drop the previous index (after appending)\n",
    "df = df.reset_index(drop=True)\n",
    "print(df)\n",
    "\n",
    "# adding a new row/case in df using loc()\n",
    "df.loc[df.last_valid_index() + 1] = [5, 5, 5]\n",
    "print()\n",
    "print(df)\n",
    "\n",
    "# making a df that consist of a new column\n",
    "df2 = pd.DataFrame({'D' : [1, 2, 3, 4, 5]})\n",
    "\n",
    "# joining df and df2 (adding a new column/variable in df)\n",
    "df = pd.DataFrame.join(df, df2)\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  2  1  5\n",
      "2  1  3  4\n",
      "\n",
      "   B  C\n",
      "0  1  5\n",
      "2  3  4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [2, 3, 1], \n",
    "                   'B': [1, 2, 3],\n",
    "                   'C': [5, 3, 4]})\n",
    "\n",
    "# dropping a row/case from a df\n",
    "df = df.drop(df.index[[1]])\n",
    "print(df)\n",
    "\n",
    "# Dropping a column by 'B' as the name of the column\n",
    "# and 1 as the axis of the column (usually always 1)\n",
    "df = df.drop('A', 1)\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Shuffling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  1  2  3\n",
      "1  2  1  5\n",
      "2  2  3  4\n",
      "3  3  4  1\n",
      "4  3  5  1\n",
      "5  4  5  3\n",
      "6  5  2  2\n",
      "\n",
      "   A  B  C\n",
      "0  1  2  3\n",
      "1  3  4  1\n",
      "2  4  5  3\n",
      "3  3  5  1\n",
      "4  5  2  2\n",
      "5  2  1  5\n",
      "6  2  3  4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': [2, 1, 2, 3, 3, 5, 4], \n",
    "                   'B': [1, 2, 3, 5, 4, 2, 5],\n",
    "                   'C': [5, 3, 4, 1, 1, 2, 3]})\n",
    "\n",
    "# sorting the data by 'A' column first and if there are same numbers\n",
    "# it will refer to column 'B' next\n",
    "df = df.sort_values(by=['A', 'B'], ascending=[True, True])\n",
    "df = df.reset_index(drop=True)\n",
    "print(df)\n",
    "\n",
    "# make a list of all index there are in df\n",
    "index = df.index.tolist()\n",
    "# shuffling the items in the index list\n",
    "np.random.shuffle(index)\n",
    "# locating the value in a certain index according\n",
    "# to the new shuffled index and putting it in the df\n",
    "df = df.loc[df.index[index]]\n",
    "df = df.reset_index(drop=True)\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating Data at Any Level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Map  Values  S    M    V\n",
      "0    0       1  6  2.0  1.0\n",
      "1    0       2  6  2.0  1.0\n",
      "2    0       3  6  2.0  1.0\n",
      "3    1       5  9  4.5  0.5\n",
      "4    1       4  9  4.5  0.5\n",
      "5    2       2  7  3.5  4.5\n",
      "6    2       5  7  3.5  4.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Map': [0, 0, 0, 1, 1, 2, 2],\n",
    "                   'Values' : [1, 2, 3, 5, 4, 2, 5]})\n",
    "\n",
    "# making some new variables/columns which consist of \n",
    "# the counting of statistical value from the items in \n",
    "# Values column that corresponds to the grouping of items\n",
    "# in 'Map' \n",
    "df['S'] = df.groupby('Map')['Values'].transform(np.sum)\n",
    "df['M'] = df.groupby('Map')['Values'].transform(np.mean)\n",
    "df['V'] = df.groupby('Map')['Values'].transform(np.var)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
